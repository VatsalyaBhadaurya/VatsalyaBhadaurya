<h1 align="center">Hi, Iâ€™m Vatsalya ðŸ‘‹</h1>

<p align="center">
Applied Robotics â€¢ Embodied AI â€¢ Humanoid Perception â€¢ Edge ML
</p>

<p align="center">
<a href="https://vatsalyaaa.me">Portfolio</a> Â·
<a href="https://www.linkedin.com/in/vatsalya-bhadaurya">LinkedIn</a> Â·
<a href="mailto:vatbhadaurya@gmail.com">Email</a>
</p>

---

### About Me

I work on real world AI systems for robotics, with a primary focus on **humanoid perception, behavior intelligence, and embodied AI**. My work lies at the intersection of applied machine learning, robotics systems engineering, and on device deployment, where models must operate reliably under real world constraints rather than controlled simulations.

I am currently an **AI Intern in the R&D team at a humanoid robotics startup**, working on perception pipelines, speech to intent to action systems, behavior logic, ROS2 based architectures, and edge deployment on Jetson platforms. I have also worked on **industrial grade vision systems deployed in automotive manufacturing environments** and authored an **IEEE research paper** on multimodal sensing systems.

---

### Current Focus

- Humanoid robotics perception and behavior systems  
- Embodied AI and decision making  
- Vision Language Action and multimodal models  
- On device machine learning optimization on Jetson platforms  
- Robotics and AI system design for real world deployment  

---

### Experience Highlights

- AI Intern in humanoid robotics R&D, working on real robots and deployed systems  
- Industrial humanoid vision system for alloy defect and paint anomaly detection for TVS Automobiles  
- IEEE published research on real time multimodal microplastic detection systems  
- Founder of MaaKosh, a maternal and neonatal health initiative focused on medical devices  
- Arduino Community Speaker with international representation  
- Multiple national level hackathon wins across AI, IoT, and robotics  

---

### Tech Stack

#### Embodied AI and Machine Learning
Vision Language Action models, Vision Language Models, large multimodal models  
YOLOv8, DINOv3, SAM 2.1, Depth Anything, DUSt3R   
Whisper, voice activity detection, speech to intent grounding  
TensorFlow, OpenCV, GPT OSS, LLaVA style architectures  

#### Edge AI and Systems Engineering
Jetson Orin Nano, Jetson Nano  
On device inference optimization under latency and memory constraints  
Dockerized deployment pipelines  
Linux based robotics systems  

#### Robotics Hardware and Embedded
STM32, Arduino, Raspberry Pi  
IMU, RGB and depth cameras, environmental sensors  
Low level sensor integration and hardware software interfacing  

---

### Research

**Development of a Real Time Multi Modal Sensor for Field Based Microplastic Detection**  
IEEE Conference IC3ECSBHI  

This work focuses on multimodal sensor fusion combining optical sensing, impedance analysis, and machine learning for real time, field deployable environmental monitoring.

---

<p align="center">
<img src="https://visitcount.itsvg.in/api?id=VatsalyaBhadaurya&icon=3&color=3"/>
</p>
