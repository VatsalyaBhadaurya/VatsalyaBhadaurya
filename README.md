<h1 align="center">Hi, Iâ€™m Vatsalya ğŸ‘‹</h1>

<p align="center">
  <img src="https://media.giphy.com/media/xTiTnHXbRoaZ1B1Mo8/giphy.gif" width="260"/>
</p>

<h3 align="center">
  Applied Robotics Â· Embodied AI Â· Humanoid Perception Â· Edge ML
</h3>

<p align="center">
  <a href="https://vatsalyaaa.me">
    <img src="https://img.shields.io/badge/Portfolio-000000?style=for-the-badge&logo=vercel&logoColor=white"/>
  </a>
  &nbsp;
  <a href="https://www.linkedin.com/in/vatsalya-bhadaurya">
    <img src="https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white"/>
  </a>
  &nbsp;
  <a href="mailto:vatbhadaurya@gmail.com">
    <img src="https://img.shields.io/badge/Email-4A4A4A?style=for-the-badge&logo=gmail&logoColor=white"/>
  </a>
</p>

---

<p align="center">
  <img src="https://media.giphy.com/media/l3vR85PnGsBwu1PFK/giphy.gif" width="520"/>
</p>

## ğŸ§  About Me

<p align="center" style="font-size: 17px;">
I build <b>real-world AI systems for robotics</b>, focused on  
<b>humanoid perception, behavior intelligence, and embodied decision-making</b>.
</p>

<p align="center" style="font-size: 16px;">
My work sits at the intersection of applied machine learning,  
robotics systems engineering, and on-device deployment â€”  
where systems must survive noisy sensors, limited compute,  
and real environments, not just simulations.
</p>

<p align="center" style="font-size: 16px;">
Currently, I am an <b>AI Intern in the R&D team at a humanoid robotics startup</b>,  
working on perception pipelines, speech â†’ intent â†’ action systems,  
behavior logic, ROS2 architectures, and edge deployment on  
<b>NVIDIA Jetson platforms</b>.
</p>

---

<p align="center">
  <img src="https://media.giphy.com/media/26tn33aiTi1jkl6H6/giphy.gif" width="520"/>
</p>

## ğŸ”¬ Current Focus

<p align="center" style="font-size: 16px; line-height: 1.8;">
Humanoid perception & behavior systems<br/>
Embodied AI and decision-making under uncertainty<br/>
Visionâ€“Languageâ€“Action & multimodal models<br/>
Edge ML optimization on Jetson platforms<br/>
Robotics AI designed for real-world deployment
</p>

---

<p align="center">
  <img src="https://media.giphy.com/media/3oKIPEqDGUULpEU0aQ/giphy.gif" width="520"/>
</p>

## ğŸ—ï¸ Experience Highlights

<p align="center" style="font-size: 16px; line-height: 1.8;">
AI Intern â€” Humanoid Robotics R&D (real robots, deployed systems)<br/>
Industrial humanoid vision system for alloy & paint defect detection (TVS Automobiles)<br/>
IEEE research on real-time multimodal microplastic detection<br/>
Founder â€” <b>MaaKosh</b>, maternal & neonatal health initiative<br/>
Arduino Community Speaker (international representation)<br/>
Multiple national-level hackathon wins (AI Â· IoT Â· Robotics)
</p>

---

## âš™ï¸ Tech Stack

<h3 align="center">Embodied AI & Machine Learning</h3>

<p align="center" style="font-size: 15.5px;">
Visionâ€“Languageâ€“Action models Â· Visionâ€“Language Models Â· Multimodal models<br/>
YOLOv8 Â· DINOv3 Â· SAM 2.1 Â· Depth Anything Â· DUSt3R<br/>
Whisper Â· Voice Activity Detection Â· Speech-to-Intent Grounding<br/>
TensorFlow Â· OpenCV Â· GPT-OSS Â· LLaVA-style architectures
</p>

<br/>

<h3 align="center">Edge AI & Systems Engineering</h3>

<p align="center" style="font-size: 15.5px;">
Jetson Orin Nano Â· Jetson Nano<br/>
On-device inference optimization (latency & memory constrained)<br/>
Dockerized deployment pipelines<br/>
Linux-based robotics systems
</p>

<br/>

<h3 align="center">Robotics Hardware & Embedded</h3>

<p align="center" style="font-size: 15.5px;">
STM32 Â· Arduino Â· Raspberry Pi<br/>
IMU Â· RGB & depth cameras Â· environmental sensors<br/>
Low-level sensor integration & hardwareâ€“software interfacing
</p>

---

## ğŸ“„ Research

<p align="center" style="font-size: 17px;">
<b>Development of a Real-Time Multimodal Sensor for Field-Based Microplastic Detection</b><br/>
<i>IEEE Conference â€” IC3ECSBHI</i>
</p>

<p align="center" style="font-size: 15.5px;">
Multimodal sensor fusion combining optical sensing,  
impedance analysis, and machine learning for  
real-time, field-deployable environmental monitoring.
</p>

---

<p align="center">
  <img src="https://media.giphy.com/media/3o7qE1YN7aBOFPRw8E/giphy.gif" width="340"/>
</p>

<p align="center">
  <i>Building robots that perceive, reason, and act â€” outside the lab.</i>
</p>
