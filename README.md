<h1 align="center">Hi, Iâ€™m Vatsalya ğŸ‘‹</h1>

<h3 align="center">
  Applied Robotics Â· Embodied AI Â· Humanoid Perception Â· Edge ML
</h3>

<p align="center">
  <a href="https://vatsalyaaa.me">
    <img src="https://img.shields.io/badge/Portfolio-000000?style=for-the-badge&logo=vercel&logoColor=white"/>
  </a>
  &nbsp;
  <a href="https://www.linkedin.com/in/vatsalya-bhadaurya">
    <img src="https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white"/>
  </a>
  &nbsp;
  <a href="mailto:vatbhadaurya@gmail.com">
    <img src="https://img.shields.io/badge/Email-4A4A4A?style=for-the-badge&logo=gmail&logoColor=white"/>
  </a>
</p>

---

<p align="center">
  <img src="https://media.giphy.com/media/l3vR85PnGsBwu1PFK/giphy.gif" width="520"/>
</p>

<h2 align="center">â–¸ About Me â—‚</h2>

<p align="center" style="font-size: 17px;">
I build <b>real-world AI systems for robotics</b>, focused on  
<b>humanoid perception, behavior intelligence, and embodied decision-making</b>.
</p>

<p align="center" style="font-size: 16px;">
My work sits at the intersection of applied machine learning,  
robotics systems engineering, and on-device deployment â€”  
where systems must survive noisy sensors, limited compute,  
and real environments, not just simulations.
</p>

<p align="center" style="font-size: 16px;">
Currently, I am an <b>AI Intern in the R&D team at a humanoid robotics startup</b>,  
working on end-to-end perception pipelines,  
speech â†’ intent â†’ action systems, behavior logic,  
ROS2 architectures, and edge deployment on  
<b>NVIDIA Jetson platforms</b>.
</p>

---

<h2 align="center">â–¸ Current Focus â—‚</h2>

<p align="center" style="font-size: 16px; line-height: 1.9;">
Humanoid perception & behavior systems<br/>
Embodied AI and decision-making under uncertainty<br/>
Visionâ€“Languageâ€“Action & multimodal models<br/>
Edge ML optimization on Jetson platforms<br/>
Robotics AI designed for real-world deployment
</p>

---

<h2 align="center">â–¸ Experience Highlights â—‚</h2>

<p align="center" style="font-size: 16px; line-height: 1.9;">
AI Intern â€” Humanoid Robotics R&D (real robots, deployed systems)<br/>
Industrial humanoid vision system for alloy & paint defect detection (TVS Automobiles)<br/>
IEEE research on real-time multimodal microplastic detection<br/>
Founder â€” <b>MaaKosh</b>, maternal & neonatal health initiative<br/>
Arduino Community Speaker (international representation)<br/>
Multiple national-level hackathon wins (AI Â· IoT Â· Robotics)
</p>

---

---

<h2 align="center">â–¸ Tech Stack & System Architecture â—‚</h2>

<br/>

<table width="100%">
  <tr>
    <!-- LEFT : Embodied AI & ML -->
    <td width="50%" valign="top">

<h3 align="center">ğŸ¤– Embodied AI & Machine Learning</h3>

<p align="center">
Models and perception systems enabling semantic understanding
</p>

<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/3/3a/Robotics_perception_pipeline.png" width="360"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Vision--Language--Action-4F46E5?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Multimodal%20Models-6366F1?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Embodied%20AI-7C3AED?style=for-the-badge"/>
</p>

<p align="center">
YOLOv8 Â· DINOv3 Â· SAM 2.1 Â· Depth Anything Â· DUSt3R  
<br/>
Whisper Â· VAD Â· Speech-to-Intent  
<br/>
TensorFlow Â· OpenCV Â· LLaVA-style architectures
</p>

    </td>

    <!-- RIGHT : Architecture -->
    <td width="50%" valign="top">

<h3 align="center">ğŸ—ï¸ Architecture (System Spine)</h3>

<p align="center">
Cross-cutting system design connecting perception, reasoning, and action
</p>

<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/8/8e/Sense-Plan-Act_loop.png" width="360"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/System%20Architecture-4338CA?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/ROS2--Based%20Design-1E40AF?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Modular%20Pipelines-312E81?style=for-the-badge"/>
</p>

<p align="center">
Event-driven pipelines Â· State machines Â·  
<br/>
Perception â†’ Decision â†’ Action flows
</p>

    </td>
  </tr>

  <tr>
    <!-- LEFT : Robotics & Embedded -->
    <td width="50%" valign="top">

<h3 align="center">ğŸ”§ Robotics & Embedded Systems</h3>

<p align="center">
Low-level sensing, control, and hardware interfacing
</p>

<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/6/6b/Robot_control_architecture.png" width="360"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Embedded%20Systems-0F766E?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Sensor%20Fusion-0891B2?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Low--level%20Control-2563EB?style=for-the-badge"/>
</p>

<p align="center">
STM32 Â· Arduino Â· Raspberry Pi  
<br/>
IMU Â· RGB & Depth Cameras Â· Encoders  
<br/>
Hardwareâ€“Software Co-design
</p>

    </td>

    <!-- RIGHT : Edge AI & Systems -->
    <td width="50%" valign="top">

<h3 align="center">ğŸš€ Edge AI & Systems Engineering</h3>

<p align="center">
Deployment, optimization, and real-time execution on robots
</p>

<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/5/5e/Edge_computing_architecture.png" width="360"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/NVIDIA%20Jetson-22C55E?style=for-the-badge&logo=nvidia&logoColor=white"/>
  <img src="https://img.shields.io/badge/On--device%20Inference-14B8A6?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Latency%20Optimization-0D9488?style=for-the-badge"/>
</p>

<p align="center">
Jetson Orin Nano Â· Jetson Nano  
<br/>
Docker Â· Linux Â· ROS2  
<br/>
Real-time inference under memory & latency constraints
</p>

    </td>
  </tr>
</table>

---

---

<h2 align="center">â–¸ Research â—‚</h2>

<p align="center" style="font-size: 17px;">
<b>Development of a Real-Time Multimodal Sensor for Field-Based Microplastic Detection</b><br/>
<i>IEEE Conference â€” IC3ECSBHI</i>
</p>

<p align="center" style="font-size: 15.5px;">
Multimodal sensor fusion combining optical sensing,  
impedance analysis, and machine learning for  
real-time, field-deployable environmental monitoring.
</p>

---

<p align="center">
  <img src="https://media.giphy.com/media/3o7qE1YN7aBOFPRw8E/giphy.gif" width="340"/>
</p>

<p align="center">
  <i>Building to perceive, reason, and act outside the lab.</i>
</p>
